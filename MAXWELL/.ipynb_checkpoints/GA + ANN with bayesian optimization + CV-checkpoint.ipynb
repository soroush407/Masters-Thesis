{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdcdeef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from bayes_opt import BayesianOptimization\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8299ee61",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), [2, 8, 16, 18, 19, 22, 23, 24])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), [2, 8, 16, 18, 19, 22, 23, 24])' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19472\\4251447441.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgeneration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_generations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;31m# Evaluate fitness for each feature subset in the population\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0mfitness_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfitness_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msubset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitness_scores\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_fitness_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mmax_fitness_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitness_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19472\\4251447441.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgeneration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_generations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;31m# Evaluate fitness for each feature subset in the population\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0mfitness_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfitness_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msubset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitness_scores\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_fitness_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mmax_fitness_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitness_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19472\\4251447441.py\u001b[0m in \u001b[0;36mfitness_function\u001b[1;34m(subset)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mcross_val_rmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mX_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mX_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_selected\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3505\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3634\u001b[0m                 \u001b[1;31m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3635\u001b[0m                 \u001b[1;31m#  the TypeError.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3636\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3637\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5649\u001b[0m             \u001b[1;31m# if key is not a scalar, directly raise an error (the code below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5650\u001b[0m             \u001b[1;31m# would convert to numpy arrays and raise later any way) - GH29926\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5651\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5653\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), [2, 8, 16, 18, 19, 22, 23, 24])"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 1: Load your dataset. Make sure you have a CSV file with relevant features and effort (target) column.\n",
    "# Replace 'your_dataset.csv' with your actual dataset file name and adjust the column names accordingly.\n",
    "maxwell=pd.read_csv(\"C:\\\\Users\\\\Asus\\\\Desktop\\\\Tehran university\\\\Seminar\\\\Datasets\\\\maxwell_dataset.csv\",header=None)\n",
    "columns_maxwell=['Syear','App','Har','Dba','Ifc','Source','Telonuse','Nlan','T01','T02','T03','T04','T05','T06','T07','T08','T09','T10','T11','T12','T13','T14','T15','Duration','Size','Time','Effort']\n",
    "maxwell.set_axis(columns_maxwell,axis='columns',inplace=True)\n",
    "maxwell.set_axis(range(1,63),axis=0 ,inplace=True)\n",
    "maxwell.rename_axis(\"Features\", axis=1,inplace=True)\n",
    "maxwell.rename_axis(\"Projects\", axis=0,inplace=True)\n",
    "dataset = maxwell\n",
    "\n",
    "# Step 2: Prepare the data.\n",
    "X = dataset.drop(columns=['Effort']).values  # Features\n",
    "y = dataset['Effort'].values  # Target (effort)\n",
    "\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.function(reduce_retracing=True)\n",
    "\n",
    "#=========================================================================================================================\n",
    "# Define the fitness function\n",
    "def fitness_function(subset):\n",
    "    selected_features = [feature for feature, is_selected in zip(range(X.shape[1]), subset) if is_selected]\n",
    "    if len(selected_features) == 0:\n",
    "        return float('-inf')  # Penalize subsets with no selected features\n",
    "    \n",
    "    \n",
    "    num_folds = 5\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=seed_value)\n",
    "    cross_val_rmse = []\n",
    "    \n",
    "    X_selected = X[:, selected_features]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_selected)\n",
    "    error_list=[]\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[val_index]\n",
    "        y_train, y_test = y[train_index], y[val_index]\n",
    "    \n",
    "        # Step 3: Build the ANN model.\n",
    "        model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(units=32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(units=16, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=1)  # Output layer with a single unit for regression.\n",
    "    ])\n",
    "\n",
    "        # Step 4: Compile the model.\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "        # Step 5: Train the model.\n",
    "        model.fit(X_train, y_train, epochs=5, batch_size=8, verbose=0)\n",
    "\n",
    "        # Step 6: Evaluate the model.\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "        error = np.mean(np.abs(y_pred - y_test))\n",
    "        error_list.append(error)\n",
    "        \n",
    "    return 1 / (1 + np.mean(error_list))  # Fitness is the inverse of the error (higher is better)\n",
    "#========================================================================================================================\n",
    "\n",
    "max_fitness_score=0\n",
    "max_score_features=0\n",
    "\n",
    "# Genetic Algorithm Parameters\n",
    "population_size = 10\n",
    "num_generations = 100\n",
    "crossover_rate = 0.8\n",
    "mutation_rate = 0.1\n",
    "\n",
    "# Create an initial population of feature subsets\n",
    "population = []\n",
    "for _ in range(population_size):\n",
    "    subset = [random.randint(0, 1) for _ in range(X.shape[1])]\n",
    "    population.append(subset)\n",
    "    \n",
    "# Genetic Algorithm\n",
    "for generation in range(num_generations):\n",
    "    # Evaluate fitness for each feature subset in the population\n",
    "    fitness_scores = [fitness_function(subset) for subset in population]\n",
    "    if max(fitness_scores) > max_fitness_score:\n",
    "        max_fitness_score = max(fitness_scores)\n",
    "        max_score_features =population[fitness_scores.index(max(fitness_scores))]\n",
    "    \n",
    "    # Selection\n",
    "    selected_population = sorted(population, key=lambda x: fitness_function(x), reverse=True)\n",
    "    \n",
    "    # Crossover\n",
    "    elitism_num = 2\n",
    "    offspring_population = selected_population[:elitism_num] # Elitism, preserving the top individuals\n",
    "    for i in range(0, population_size, 2):\n",
    "        parent1 = selected_population[i]\n",
    "        parent2 = selected_population[i + 1]\n",
    "        \n",
    "        if random.random() < crossover_rate:\n",
    "            crossover_point = random.randint(1, len(parent1) - 1)\n",
    "            child1 = parent1[:crossover_point] + parent2[crossover_point:]\n",
    "            child2 = parent2[:crossover_point] + parent1[crossover_point:]\n",
    "        else:\n",
    "            child1 = parent1\n",
    "            child2 = parent2\n",
    "        \n",
    "        offspring_population.append(child1)\n",
    "        offspring_population.append(child2)\n",
    "    \n",
    "    # Mutation\n",
    "    for i in range(2,population_size):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_feature = random.randint(0, X.shape[1] - 1)\n",
    "            offspring_population[i][mutated_feature] = 1 - offspring_population[i][mutated_feature]\n",
    "    \n",
    "    # Replace the old population with the new offspring population\n",
    "    population = offspring_population\n",
    "\n",
    "# Select the best feature subset from the final population\n",
    "best_subset = max(population, key=fitness_function)\n",
    "selected_features = [feature for feature, is_selected in zip(range(X.shape[1]), best_subset) if is_selected]\n",
    "\n",
    "print(selected_features)\n",
    "#======================================================================================================================    \n",
    "    \n",
    "# Define the ANN model to be optimized.\n",
    "def ann_model(neurons_input, neurons_hidden, num_hidden_layers, learning_rate):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(units=int(neurons_input), activation='relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "    for _ in range(int(num_hidden_layers)):\n",
    "        model.add(tf.keras.layers.Dense(units=int(neurons_hidden), activation='relu'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units=1))  # Output layer with a single unit for regression.\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the search space for Bayesian optimization.\n",
    "pbounds = {\n",
    "        'neurons_input': (10, 50),\n",
    "        'neurons_hidden': (10, 50),\n",
    "        'num_hidden_layers': (1, 5),\n",
    "        'learning_rate': (1e-5, 1e-2),\n",
    "        'batch_size': (8, 32),\n",
    "        'epochs': (5,20)\n",
    "}\n",
    "\n",
    "# Define the function to optimize (minimize RMSE).\n",
    "def optimize_effort_estimation(neurons_input, neurons_hidden, num_hidden_layers, learning_rate, batch_size, epochs):\n",
    "    model = ann_model(neurons_input, neurons_hidden, num_hidden_layers, learning_rate)\n",
    "    \n",
    "    model.fit(X_train, y_train, batch_size=int(batch_size), epochs=int(epochs), verbose=0)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    return -rmse  # Minimize the negative RMSE for Bayesian optimization.\n",
    "\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=seed_value)\n",
    "X_selected = X[:, selected_features]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_selected)\n",
    "mean_MAE=[]\n",
    "mean_MMRE=[]\n",
    "mean_RMSE=[]\n",
    "    \n",
    "for train_index, val_index in kf.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[val_index]\n",
    "    y_train, y_test = y[train_index], y[val_index]\n",
    "    \n",
    "    # Perform Bayesian optimization.\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=optimize_effort_estimation,\n",
    "        pbounds=pbounds,\n",
    "        random_state=42,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    optimizer.maximize(init_points=10, n_iter=30)  # Adjust the number of initial points and iterations.\n",
    "\n",
    "    # Print the best hyperparameters found.\n",
    "    best_params = optimizer.max['params']\n",
    "        \n",
    "    #build the model\n",
    "    model = ann_model(best_params['neurons_input'],best_params['neurons_hidden'],best_params['num_hidden_layers'],best_params['learning_rate'])\n",
    "    # Train the model.\n",
    "    model.fit(X_train, y_train, epochs=int(best_params['epochs']), batch_size=int(best_params['batch_size']), verbose=0)\n",
    "\n",
    "    # Step 6: Evaluate the model.\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mean_MAE.append(mae)\n",
    "\n",
    "\n",
    "    # Calculate Mean Magnitude of Relative Error (MMRE)\n",
    "    mmre = np.mean(np.abs((y_test - y_pred) / y_test))\n",
    "    mean_MMRE.append(mmre)\n",
    "\n",
    "    # Calculate the Root Mean Squared Error (RMSE) to assess the model's performance.\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mean_RMSE.append(rmse)\n",
    "                \n",
    "print(f\"Mean Absolute Error mean: {np.mean(mean_MAE)}\")               \n",
    "print(f\"Mean Magnitude of Relative Error mean (MMRE): {np.mean(mean_MMRE):.2f}\")            \n",
    "print(f\"Root Mean Squared Error (RMSE) mean: {np.mean(mean_RMSE)}\")\n",
    "#===================================================================================================================\n",
    "\n",
    "# train the model using max_features\n",
    "\n",
    "# X_selected = X[:, max_score_features]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# model3 = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Dense(units=64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "#     tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=1)  # Output layer with a single unit for regression.\n",
    "# ])\n",
    "\n",
    "#  # Step 4: Compile the model.\n",
    "# model3.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "#  # Step 5: Train the model.\n",
    "# model3.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# # You can now use the trained model for prediction or further evaluation\n",
    "# y_pred = model3.predict(X_test_scaled)\n",
    "\n",
    "# # Calculate the Root Mean Squared Error (RMSE) to assess the model's performance.\n",
    "# rmse3 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# print(f\"Root Mean Squared Error (RMSE): {rmse3}\")\n",
    "\n",
    "# # Convert y_pred and y_test to NumPy arrays\n",
    "# y_pred = np.array(y_pred).flatten()\n",
    "# y_test = np.array(y_test)\n",
    "\n",
    "# # Calculate Mean Magnitude of Relative Error (MMRE)\n",
    "# mmre = np.mean(np.abs((y_test - y_pred) / y_test))\n",
    "# print(f\"Mean Magnitude of Relative Error (MMRE): {mmre:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(best_subset,\" \\n \", max_score_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20615c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

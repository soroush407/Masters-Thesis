{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d55b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import math\n",
    "from bayes_opt import BayesianOptimization\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e141051a",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), [2, 4, 8, 11, 13, 14, 16, 18, 19, 21, 22, 23, 24, 25, 27, 29, 32, 33, 34, 36, 40, 41, 44])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), [2, 4, 8, 11, 13, 14, 16, 18, 19, 21, 22, 23, 24, 25, 27, 29, 32, 33, 34, 36, 40, 41, 44])' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22588\\3727636642.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Adjust this probability based on your problem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mnew_harmony\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnew_harmony\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[0mcurrent_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjective_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mharmony_memory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrnd_choice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[0mnew_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjective_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_harmony\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnew_obj\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mcurrent_obj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22588\\3727636642.py\u001b[0m in \u001b[0;36mobjective_function\u001b[1;34m(subset)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mcross_val_rmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mX_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mX_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_selected\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3505\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3634\u001b[0m                 \u001b[1;31m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3635\u001b[0m                 \u001b[1;31m#  the TypeError.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3636\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3637\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5649\u001b[0m             \u001b[1;31m# if key is not a scalar, directly raise an error (the code below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5650\u001b[0m             \u001b[1;31m# would convert to numpy arrays and raise later any way) - GH29926\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5651\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5653\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), [2, 4, 8, 11, 13, 14, 16, 18, 19, 21, 22, 23, 24, 25, 27, 29, 32, 33, 34, 36, 40, 41, 44])"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Load your dataset. Make sure you have a CSV file with relevant features and effort (target) column.\n",
    "# Replace 'your_dataset.csv' with your actual dataset file name and adjust the column names accordingly.\n",
    "Nasa=pd.read_csv(\"C:\\\\Users\\\\Asus\\\\Desktop\\\\Tehran university\\\\Seminar\\\\Datasets\\\\cocomonasa_2_dataset.csv\",header=None,index_col=0)\n",
    "columns_Nasa=['ProjName','CatofApp','ForG','Center','YearofDev','DevMode','rely','data','cplx','time','stor','virt','turn','acap','aexp','pcap','vexp','lexp','modp','tool','sced','loc','Effort']\n",
    "Nasa.set_axis(columns_Nasa,axis='columns',inplace=True)\n",
    "Nasa.rename_axis(\"Features\", axis=1,inplace=True)\n",
    "Nasa.rename_axis(\"Projects ID\", axis=0,inplace=True)\n",
    "Nasa.reset_index(inplace=True)\n",
    "Nasa.drop(columns=['Projects ID'], inplace=True)\n",
    "\n",
    "#Nasa dataset preprocessing\n",
    "def NASA_quantifier(x):\n",
    "    if x=='vl':\n",
    "        return 0\n",
    "    elif x=='l':\n",
    "        return 1\n",
    "    elif x=='n':\n",
    "        return 2\n",
    "    elif x=='h':\n",
    "        return 3\n",
    "    elif x=='vh':\n",
    "        return 4\n",
    "    elif x=='xh':\n",
    "        return 5\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "Nasa=Nasa.applymap(NASA_quantifier)\n",
    "dataset = Nasa\n",
    "\n",
    "# Step 2: Prepare the data.\n",
    "X = dataset.drop(columns=['Effort'])  # Features\n",
    "y = dataset['Effort'].values  # Target (effort)\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.function(reduce_retracing=True)\n",
    "\n",
    "\n",
    "# Step 3: Feature Selection using Harmony Search\n",
    "def objective_function(subset):\n",
    "    selected_features = [feature for feature, is_selected in zip(range(X.shape[1]), subset) if is_selected]\n",
    "    if len(selected_features) == 0:\n",
    "        return float('-inf')  # Penalize subsets with no selected features\n",
    "    \n",
    "    \n",
    "    num_folds = 5\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=seed_value)\n",
    "    cross_val_rmse = []\n",
    "    \n",
    "    X_selected = X.iloc[:, selected_features]\n",
    "    X_selected = pd.get_dummies(X_selected)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_selected)\n",
    "    error_list=[]\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[val_index]\n",
    "        y_train, y_test = y[train_index], y[val_index]\n",
    "    \n",
    "        # Step 3: Build the ANN model.\n",
    "        model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(units=32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(units=16, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=1)  # Output layer with a single unit for regression.\n",
    "    ])\n",
    "\n",
    "        # Step 4: Compile the model.\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "        # Step 5: Train the model.\n",
    "        model.fit(X_train, y_train, epochs=5, batch_size=8, verbose=0)\n",
    "\n",
    "        # Step 6: Evaluate the model.\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "        error = np.mean(np.abs(y_pred - y_test))\n",
    "        error_list.append(error)\n",
    "        \n",
    "    return 1 / (1 + np.mean(error_list))  # Fitness is the inverse of the error (higher is better)\n",
    "#====================================================================================================================\n",
    "# Harmony Search Parameters\n",
    "num_features = X.shape[1]\n",
    "hms = 20  # Harmony memory size\n",
    "iterations = 100  # Number of iterations\n",
    "\n",
    "# Initialize harmony memory\n",
    "harmony_memory = np.random.randint(0, 2, size=(hms, num_features))\n",
    "\n",
    "# Harmony Search Algorithm\n",
    "for _ in range(iterations):\n",
    "    rnd_choice=np.random.choice(hms)\n",
    "    new_harmony = np.copy(harmony_memory[rnd_choice])\n",
    "    for i in range(num_features):\n",
    "        if np.random.rand() < 0.5:  # Adjust this probability based on your problem\n",
    "            new_harmony[i] = 1 - new_harmony[i]\n",
    "    current_obj = objective_function(harmony_memory[rnd_choice])\n",
    "    new_obj = objective_function(new_harmony)\n",
    "    if new_obj < current_obj:\n",
    "        harmony_memory[rnd_choice] = new_harmony\n",
    "\n",
    "# Get selected features based on final harmony memory\n",
    "selected_features = harmony_memory[np.argmax([objective_function(i) for i in harmony_memory])]\n",
    "print(selected_features)\n",
    "#======================================================================================================================\n",
    "\n",
    "#if len(selected_features) == 0:\n",
    "#   return float('-inf')  # Penalize subsets with no selected features\n",
    "    \n",
    "    \n",
    "# Define the ANN model to be optimized.\n",
    "def ann_model(neurons_input, neurons_hidden, num_hidden_layers, learning_rate):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(units=int(neurons_input), activation='relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "    for _ in range(int(num_hidden_layers)):\n",
    "        model.add(tf.keras.layers.Dense(units=int(neurons_hidden), activation='relu'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units=1))  # Output layer with a single unit for regression.\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the search space for Bayesian optimization.\n",
    "pbounds = {\n",
    "        'neurons_input': (10, 50),\n",
    "        'neurons_hidden': (10, 50),\n",
    "        'num_hidden_layers': (1, 5),\n",
    "        'learning_rate': (1e-5, 1e-2),\n",
    "        'batch_size': (8,32 ),\n",
    "        'epochs': (5, 20)\n",
    "}\n",
    "\n",
    "# Define the function to optimize (minimize RMSE).\n",
    "def optimize_effort_estimation(neurons_input, neurons_hidden, num_hidden_layers, learning_rate, batch_size, epochs):\n",
    "    model = ann_model(neurons_input, neurons_hidden, num_hidden_layers, learning_rate)\n",
    "    \n",
    "    model.fit(X_train, y_train, batch_size=int(batch_size), epochs=int(epochs), verbose=0)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    return -rmse  # Minimize the negative RMSE for Bayesian optimization.\n",
    "\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=seed_value)\n",
    "X_selected = X.iloc[:, selected_features]\n",
    "X_selected = pd.get_dummies(X_selected)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_selected)\n",
    "mean_MAE=[]\n",
    "mean_MMRE=[]\n",
    "mean_RMSE=[]\n",
    "    \n",
    "for train_index, val_index in kf.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[val_index]\n",
    "    y_train, y_test = y[train_index], y[val_index]\n",
    "    \n",
    "    # Perform Bayesian optimization.\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=optimize_effort_estimation,\n",
    "        pbounds=pbounds,\n",
    "        random_state=42,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    optimizer.maximize(init_points=10, n_iter=30)  # Adjust the number of initial points and iterations.\n",
    "\n",
    "    # Print the best hyperparameters found.\n",
    "    best_params = optimizer.max['params']\n",
    "        \n",
    "    #build the model\n",
    "    model = ann_model(best_params['neurons_input'],best_params['neurons_hidden'],best_params['num_hidden_layers'],best_params['learning_rate'])\n",
    "    # Train the model.\n",
    "    model.fit(X_train, y_train, epochs=int(best_params['epochs']), batch_size=int(best_params['batch_size']), verbose=0)\n",
    "\n",
    "    # Step 6: Evaluate the model.\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mean_MAE.append(mae)\n",
    "\n",
    "\n",
    "    # Calculate Mean Magnitude of Relative Error (MMRE)\n",
    "    mmre = np.mean(np.abs((y_test - y_pred) / y_test))\n",
    "    mean_MMRE.append(mmre)\n",
    "\n",
    "    # Calculate the Root Mean Squared Error (RMSE) to assess the model's performance.\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mean_RMSE.append(rmse)\n",
    "                \n",
    "print(f\"Mean Absolute Error mean: {np.mean(mean_MAE)}\")               \n",
    "print(f\"Mean Magnitude of Relative Error mean (MMRE): {np.mean(mean_MMRE):.2f}\")            \n",
    "print(f\"Root Mean Squared Error (RMSE) mean: {np.mean(mean_RMSE)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdd7150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

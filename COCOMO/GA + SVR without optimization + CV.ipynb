{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb6b57d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split , KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import tensorflow as tf\n",
    "cocomo=pd.read_csv(\"C:\\\\Users\\\\Asus\\\\Desktop\\\\Tehran university\\\\Seminar\\\\Datasets\\\\cocomo81_dataset.csv\",header=None)\n",
    "columns_cocomo=['rely','data','cplx','time','stor','virt','turn','acap','aexp','pcap','vexp','lexp','modp','tool','sced','loc','actual']\n",
    "cocomo.set_axis(columns_cocomo,axis='columns',inplace=True)\n",
    "cocomo.set_axis(range(1,64),axis=0 ,inplace=True)\n",
    "cocomo.rename_axis(\"Features\", axis=1,inplace=True)\n",
    "cocomo.rename_axis(\"Projects\", axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11c623e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error mean: 620.2411983129797\n",
      "Mean Magnitude of Relative Error mean (MMRE): 1.94\n",
      "Root Mean Squared Error (RMSE) mean: 1402.2037158436656\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define your dataset (X) and corresponding effort values (y)\n",
    "# Replace X and y with your actual dataset\n",
    "\n",
    "# Feature matrix X should have shape (n_samples, n_features)\n",
    "X = cocomo.drop('actual',axis=1).values\n",
    "# Target values y should have shape (n_samples,)\n",
    "y = cocomo['actual'].values\n",
    "\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Genetic Algorithm Parameters\n",
    "population_size = 20\n",
    "num_generations = 100\n",
    "crossover_rate = 0.8\n",
    "mutation_rate = 0.1\n",
    "\n",
    "# Create an initial population of feature subsets\n",
    "population = []\n",
    "for _ in range(population_size):\n",
    "    subset = [random.randint(0, 1) for _ in range(X.shape[1])]\n",
    "    population.append(subset)\n",
    "\n",
    "# Define the fitness function\n",
    "def fitness_function(subset):\n",
    "    selected_features = [feature for feature, is_selected in zip(range(X.shape[1]), subset) if is_selected]\n",
    "    if len(selected_features) == 0:\n",
    "        return float('-inf')  # Penalize subsets with no selected features\n",
    "    \n",
    "    num_folds = 5\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=seed_value)\n",
    "    \n",
    "    X_selected = X[:, selected_features]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_selected)\n",
    "    error_list=[]\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[val_index]\n",
    "        y_train, y_test = y[train_index], y[val_index]\n",
    "    \n",
    "    \n",
    "        # Step 3: Build the ANN model.\n",
    "        model = SVR(kernel='linear')\n",
    "\n",
    "        # Step 5: Train the model.\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Step 6: Evaluate the model.\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "        error = np.mean(np.abs(y_pred - y_test))\n",
    "        error_list.append(error)\n",
    "        \n",
    "    return 1 / (1 + np.mean(error_list)) \n",
    "    \n",
    "    \n",
    "max_fitness_score=0\n",
    "max_score_features=0\n",
    "\n",
    "# Genetic Algorithm\n",
    "for generation in range(num_generations):\n",
    "    # Evaluate fitness for each feature subset in the population\n",
    "    fitness_scores = [fitness_function(subset) for subset in population]\n",
    "    if max(fitness_scores) > max_fitness_score:\n",
    "        max_fitness_score = max(fitness_scores)\n",
    "        max_score_features =population[fitness_scores.index(max(fitness_scores))]\n",
    "    \n",
    "    # Selection\n",
    "    selected_population = sorted(population, key=lambda x: fitness_function(x), reverse=True)\n",
    "    \n",
    "    # Crossover\n",
    "    offspring_population = selected_population[:2] # Elitism, preserving the top two individuals\n",
    "    for i in range(0, population_size, 2):\n",
    "        parent1 = selected_population[i]\n",
    "        parent2 = selected_population[i + 1]\n",
    "        \n",
    "        if random.random() < crossover_rate:\n",
    "            crossover_point = random.randint(1, len(parent1) - 1)\n",
    "            child1 = parent1[:crossover_point] + parent2[crossover_point:]\n",
    "            child2 = parent2[:crossover_point] + parent1[crossover_point:]\n",
    "        else:\n",
    "            child1 = parent1\n",
    "            child2 = parent2\n",
    "        \n",
    "        offspring_population.append(child1)\n",
    "        offspring_population.append(child2)\n",
    "    \n",
    "    # Mutation\n",
    "    for i in range(2,population_size):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_feature = random.randint(0, X.shape[1] - 1)\n",
    "            offspring_population[i][mutated_feature] = 1 - offspring_population[i][mutated_feature]\n",
    "    \n",
    "    # Replace the old population with the new offspring population\n",
    "    population = offspring_population\n",
    "\n",
    "# Select the best feature subset from the final population\n",
    "best_subset = max(population, key=fitness_function)\n",
    "selected_features = [feature for feature, is_selected in zip(range(X.shape[1]), best_subset) if is_selected]\n",
    "\n",
    "\n",
    "#======================================================================================================================\n",
    "\n",
    "# Train the final model using the selected features\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=seed_value)\n",
    "    \n",
    "X_selected = X[:, selected_features]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "mean_MAE=[]\n",
    "mean_MMRE=[]\n",
    "mean_RMSE=[]\n",
    "    \n",
    "for train_index, val_index in kf.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[val_index]\n",
    "    y_train, y_test = y[train_index], y[val_index]\n",
    "    \n",
    "    \n",
    "    # Step 3: Build the ANN model.\n",
    "    model = SVR(kernel='linear')\n",
    "\n",
    "    # Step 5: Train the model.\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Step 6: Evaluate the model.\n",
    "    y_pred = model.predict(X_test)\n",
    "        \n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mean_MAE.append(mae)\n",
    "\n",
    "    # Calculate the Root Mean Squared Error (RMSE) for this fold.\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mean_RMSE.append(rmse)\n",
    "\n",
    "     # Convert y_pred and y_test to NumPy arrays for MMRE calculation\n",
    "    y_pred = np.array(y_pred).flatten()\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Calculate the Mean Magnitude of Relative Error (MMRE) for this fold.\n",
    "    mmre = np.mean(np.abs((y_test - y_pred) / y_test))\n",
    "    mean_MMRE.append(mmre)\n",
    "\n",
    "print(f\"Mean Absolute Error mean: {np.mean(mean_MAE)}\")   \n",
    "print(f\"Mean Magnitude of Relative Error mean (MMRE): {np.mean(mean_MMRE):.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE) mean: {np.mean(mean_RMSE)}\")\n",
    "#===================================================================================================================\n",
    "\n",
    "# train the model using max_features\n",
    "\n",
    "# X_selected = X[:, max_score_features]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# model3 = SVR(kernel = 'linear')\n",
    "\n",
    "#  # Step 5: Train the model.\n",
    "# model3.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # You can now use the trained model for prediction or further evaluation\n",
    "# y_pred = model3.predict(X_test_scaled)\n",
    "\n",
    "# # Calculate the Root Mean Squared Error (RMSE) to assess the model's performance.\n",
    "# rmse3 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# print(f\"Root Mean Squared Error (RMSE3): {rmse3}\")\n",
    "\n",
    "# # Convert y_pred and y_test to NumPy arrays\n",
    "# y_pred = np.array(y_pred).flatten()\n",
    "# y_test = np.array(y_test)\n",
    "\n",
    "# # Calculate Mean Magnitude of Relative Error (MMRE)\n",
    "# mmre = np.mean(np.abs((y_test - y_pred) / y_test))\n",
    "# print(f\"Mean Magnitude of Relative Error (MMRE3): {mmre:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(best_subset,\" \\n \", max_score_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0624345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
